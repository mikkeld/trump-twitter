{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data(path, years):\n",
    "    return pd.concat([pd.read_json(path.format(year)) for year in years])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TRUMP_DATA_PATH = './trump-tweet-archive/data/realdonaldtrump/{}.json'\n",
    "AVAILABLE_YEARS = list(range(2009, 2018))\n",
    "trump_dataframe = get_data(TRUMP_DATA_PATH, AVAILABLE_YEARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>id_str</th>\n",
       "      <th>in_reply_to_user_id_str</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-12-23 17:38:18</td>\n",
       "      <td>12</td>\n",
       "      <td>6971079756</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>28</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>From Donald Trump: Wishing everyone a wonderfu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-12-03 19:39:09</td>\n",
       "      <td>6</td>\n",
       "      <td>6312794445</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>33</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>Trump International Tower in Chicago ranked 6t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-11-26 19:55:38</td>\n",
       "      <td>11</td>\n",
       "      <td>6090839867</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>Wishing you and yours a very Happy and Bountif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-11-16 21:06:10</td>\n",
       "      <td>3</td>\n",
       "      <td>5775731054</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>Donald Trump Partners with TV1 on New Reality ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-11-02 14:57:56</td>\n",
       "      <td>6</td>\n",
       "      <td>5364614040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>--Work has begun, ahead of schedule, to build ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           created_at  favorite_count      id_str  in_reply_to_user_id_str  \\\n",
       "0 2009-12-23 17:38:18              12  6971079756                      NaN   \n",
       "1 2009-12-03 19:39:09               6  6312794445                      NaN   \n",
       "2 2009-11-26 19:55:38              11  6090839867                      NaN   \n",
       "3 2009-11-16 21:06:10               3  5775731054                      NaN   \n",
       "4 2009-11-02 14:57:56               6  5364614040                      NaN   \n",
       "\n",
       "  is_retweet  retweet_count              source  \\\n",
       "0      False             28  Twitter Web Client   \n",
       "1      False             33  Twitter Web Client   \n",
       "2      False             13  Twitter Web Client   \n",
       "3      False              5  Twitter Web Client   \n",
       "4      False              7  Twitter Web Client   \n",
       "\n",
       "                                                text  \n",
       "0  From Donald Trump: Wishing everyone a wonderfu...  \n",
       "1  Trump International Tower in Chicago ranked 6t...  \n",
       "2  Wishing you and yours a very Happy and Bountif...  \n",
       "3  Donald Trump Partners with TV1 on New Reality ...  \n",
       "4  --Work has begun, ahead of schedule, to build ...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trump_text_file = '. '.join([t for t in trump_dataframe['text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From Donald Trump: Wishing everyone a wonderful holiday & a happy, healthy, prosperous New Year. Let’s think like champions in 2010!. Trump International Tower in Chicago ranked 6th tallest building in world by Council on Tall Buildings & Urban Habitat http://bit.ly/sqvQq. Wishing you and yours a very Happy and Bountiful Thanksgiving!. Donald Trump Partners with TV1 on New Reality Series Entitled, Omarosa\\'s Ultimate Merger: http://tinyurl.com/yk5m3lc. --Work has begun, ahead of schedule, to build the greatest golf course in history: Trump International – Scotland.. --From Donald Trump: \"Ivanka and Jared’s wedding was spectacular, and they make a beautiful couple. I’m a very proud father.\". Hear Donald Trump discuss big gov spending, banks, & taxes on Your World w/Neil Cavuto: http://tinyurl.com/yhnzd7p. Watch video of Ivanka Trump sharing business advice with 4 entrepreneurial women on GMA: http://tinyurl.com/yk6hlfo. - Read what Donald Trump has to say about daughter Ivanka\\'s upcoming'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump_text_file[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflowing\n",
    "* The hard part will be handling variable length input\n",
    "* As for the output. we just cap it at 140 and go back to the latest dot (.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_steps = 20\n",
    "n_hidden = 512\n",
    "n_units = 3\n",
    "embedding_size = 100\n",
    "batch_size = 64\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def word_vocab(df):\n",
    "    count = Counter(df.split(' ')).most_common()\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "    reversed_dictionary = dict(zip(dictionary.values(), \n",
    "                               dictionary.keys()))\n",
    "    vocab_size = len(dictionary)\n",
    "    idx = [dictionary[w] for w in df.split(' ')]\n",
    "    return dictionary, reversed_dictionary, vocab_size, idx\n",
    "\n",
    "dictionary, reversed_dictionary, vocab_size, idx = word_vocab(trump_text_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vocab(df):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        dataframe: Pandas dataseries with tweets\n",
    "    Returns:\n",
    "        w_to_id: word to id from vocab\n",
    "        id_to_w: id to word from vocab\n",
    "        idx: vocab in ids\n",
    "    \"\"\"\n",
    "    vocab = set(c for t in df for c in t)\n",
    "    vocab_size = len(vocab)\n",
    "    w_to_id = {w: i for i, w in enumerate(vocab)}\n",
    "    id_to_w = {i: w for i, w in enumerate(vocab)}\n",
    "    idx = [w_to_id[c] for c in df]\n",
    "    return w_to_id, id_to_w, idx, vocab_size\n",
    "\n",
    "w_to_id, id_to_w, idx, vocab_size = vocab(trump_text_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_input_and_output(dataframe, n_steps=n_steps):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        dataframe: Pandas dataseries with all text\n",
    "    Returns:\n",
    "        c_input_transformed: Input in a numpy array format for time series\n",
    "        c_target_transformed: Target character in a numpy array for time series\n",
    "    \"\"\"\n",
    "    c_input = [[dataframe[i+j] for i in range(0, len(dataframe)-n_steps, n_steps)]\n",
    "               for j in range(n_steps)]\n",
    "    c_target = [dataframe[i+n_steps] for i in range(0, len(dataframe)-n_steps, n_steps)]\n",
    "    c_input_transformed = np.array(np.stack(c_input, axis=1), dtype=np.int32)\n",
    "    c_target_transformed = np.array(np.stack(c_target), dtype=np.int32)\n",
    "    return c_input_transformed, c_target_transformed\n",
    "\n",
    "c_inputs, c_target = make_input_and_output(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_model(inputs):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        n_layers: Number of layers in the hidden layers\n",
    "        n_units: Number of LSTM units\n",
    "    Returns:\n",
    "        Logits and probabilities\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def input_fn():  \n",
    "    \"\"\"\n",
    "    Args:\n",
    "        inputs: numpy array with chars\n",
    "        labels: numpy array with labels\n",
    "        batch_size: Size of batch\n",
    "      \n",
    "    Returns:\n",
    "        X: size of [batch_size, sequence_length, 1]\n",
    "        y: size of [batch_size, 1]        \n",
    "    \"\"\"\n",
    "    n_examples = len(c_inputs)\n",
    "    batch_idx = np.random.choice(\n",
    "        n_examples,\n",
    "        size=batch_size,\n",
    "        replace=False)\n",
    "    \n",
    "    x_batch = c_inputs[batch_idx, :]\n",
    "    y_batch = c_target[batch_idx]\n",
    "    seq_length = np.array([len(x) for x in x_batch], dtype=np.int32)\n",
    "  \n",
    "    return x_batch, y_batch    \n",
    "\n",
    "def train(n_epochs, outlook_size):\n",
    "    \"\"\"\n",
    "    Args: \n",
    "        n_epocs: Number of epochs to run the model for\n",
    "    Returns:\n",
    "        probabilities: Softmax probabilities for all words\n",
    "        outlook_size: Number of steps to predict out   \n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_out 11.2964\n",
      "loss_out 11.6237\n",
      "loss_out 9.42237\n",
      "['would', 'would', 'would', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'having', 'would', 'would', 'would', 'of', 'would', 'the', 'having', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'having', 'the', 'the', 'the', 'the', 'the', 'the', 'would', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the']\n"
     ]
    }
   ],
   "source": [
    "#Test TF\n",
    "with tf.Graph().as_default():\n",
    "    with tf.name_scope(\"placeholders\"):\n",
    "        x = tf.placeholder(dtype=tf.int32, shape=[None, n_steps])\n",
    "        y = tf.placeholder(dtype=tf.int32, shape=[None])\n",
    "        seq_length = tf.placeholder(tf.int32, [None])\n",
    "    \n",
    "    # Let's set up the embedding converting words to vectors\n",
    "    with tf.name_scope(\"embeddings\"):\n",
    "        embeddings = tf.Variable(tf.random_uniform(shape=[vocab_size, embedding_size], minval=-1, maxval=1))\n",
    "        train_input = tf.nn.embedding_lookup(embeddings, x)\n",
    "    \n",
    "    with tf.name_scope(\"model\"):\n",
    "        basic_cell = tf.nn.rnn_cell.GRUCell(num_units=n_hidden)\n",
    "        outputs, states = tf.nn.dynamic_rnn(basic_cell, train_input, dtype=tf.float32)\n",
    "\n",
    "        logits = tf.layers.dense(states, units=vocab_size, activation=None)\n",
    "        predictions = tf.nn.softmax(logits)\n",
    "        xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            labels=y,\n",
    "            logits=logits)\n",
    "        loss = tf.reduce_mean(xentropy)\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "        training_op = optimizer.minimize(loss)\n",
    "        \n",
    "        tf.summary.scalar('cross_entropy', loss)\n",
    "        merged = tf.summary.merge_all()\n",
    "        saver = tf.train.Saver()\n",
    "        train_writer = tf.summary.FileWriter('./trump/loss',\n",
    "                                      sess.graph)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for r in range(30):\n",
    "            x_batch, y_batch = input_fn()\n",
    "            feed_dict = {x: x_batch, y: y_batch}\n",
    "            _, summary, loss_out = sess.run([training_op, merged, loss], feed_dict=feed_dict)\n",
    "            if r % 10 == 0:\n",
    "                save_path = saver.save(sess, \"/tmp/trump/trump_model{}.ckpt\".format(r))\n",
    "                train_writer.add_summary(summary, r)\n",
    "                print(\"loss_out\", loss_out)\n",
    "            \n",
    "        sample_text = \"From Donald Trump: Wishing everyone a wonderful holiday & a happy, healthy, prosperous New Year. Let’s think like champions in 2010!. Trump International Tower in Chicago ranked 6th tallest building in world by Council on Tall Buildings & Urban Habitat http://bit.ly/sqvQq. Wishing you and yours a very Happy Happy Happy Happy\"\n",
    "        \n",
    "        all_predictions = []\n",
    "        current_text = sample_text.split(' ')[:20]\n",
    "        for i in range(50):\n",
    "            sample_text_ids = np.expand_dims(np.array([dictionary[c] for c in current_text], dtype=np.int32), 0)\n",
    "            prediction_out = sess.run([predictions], feed_dict={x: sample_text_ids})\n",
    "            prediction_c = reversed_dictionary[np.argmax(prediction_out)]\n",
    "            all_predictions.append(prediction_c)\n",
    "            current_text = current_text[1:] + [prediction_c]\n",
    "            \n",
    "        print(all_predictions)  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Donald',\n",
       " 'Trump:',\n",
       " 'Wishing',\n",
       " 'everyone',\n",
       " 'a',\n",
       " 'wonderful',\n",
       " 'holiday',\n",
       " '&',\n",
       " 'a',\n",
       " 'happy,',\n",
       " 'healthy,',\n",
       " 'prosperous',\n",
       " 'New',\n",
       " 'Year.',\n",
       " 'Let’s',\n",
       " 'think',\n",
       " 'like',\n",
       " 'champions',\n",
       " 'in',\n",
       " 'is']"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = \"From Donald Trump: Wishing everyone a wonderful holiday & a happy, healthy, prosperous New Year. Let’s think like champions in 2010!. Trump International Tower in Chicago ranked 6th tallest building in world by Council on Tall Buildings & Urban Habitat http://bit.ly/sqvQq. Wishing you and yours a very Happy\"\n",
    "all_predictions = []\n",
    "current_text = sample_text.split(' ')[:20]\n",
    "sample_text_ids = np.expand_dims(np.array([dictionary[c] for c in current_text], dtype=np.int32), 0)\n",
    "prediction_c = reversed_dictionary[5]\n",
    "all_predictions.append(prediction_c)\n",
    "c = current_text[1:] + [prediction_c]\n",
    "c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
